import sys
import os
import cv2
import gc
import torch
current_dir = os.path.dirname(os.path.abspath(__file__)) # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ä¸Šä¸€çº§ï¼ˆé¡¹ç›®æ ¹ç›®å½•ï¼‰
parent_dir = os.path.dirname(current_dir)  # å°±æ˜¯ project_root
sys.path.append(parent_dir) # å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ Python æ¨¡å—æœç´¢è·¯å¾„

from inference.segmentation.yolo_segment import SegModel


from PySide2.QtCore import QObject
from PySide2.QtWidgets import QApplication, QWidget, QPushButton, QVBoxLayout, QFileDialog
from PySide2.QtGui import QImage, QPixmap
from PySide2.QtCore import Qt
from PySide2.QtCore import QTimer, QThreadPool
import numpy as np
import queue
import threading



# åŠ è½½æœ¬åœ°åŒ…
from .source.camera import VideoSource,SourceType
from .workers.seg_worker import SegWorker
from .workers.postprocess_worker import OutputProcessorTask

from logs.logger import DailyLogger

class VideoChannel(QObject):
    def __init__(self, display_label,ui):
        super().__init__()
        self.label  = display_label  # æ‹¿åˆ°ç”»é¢çš„UI
        self.ui = ui
        self.log = DailyLogger("è§†é¢‘æºæ¨æµ")
        self.model = None
        self.VS = VideoSource()  # è§†é¢‘å¤„ç†
        self.timer = QTimer()  # è§†é¢‘æ’­æ”¾å®šæ—¶å™¨
        self.timer.timeout.connect(self.play_frame)  # æ¯æ¬¡è§¦å‘æ’­æ”¾ä¸€å¸§
        # self.threadpool = QThreadPool()  # çº¿ç¨‹æ±  ç®¡ç†å­çº¿ç¨‹
        # self.threadpool.setMaxThreadCount(3)  # 1 ä¸ªæ¨ç†çº¿ç¨‹ + 2 ä¸ªå¤„ç†çº¿ç¨‹
        self.inference_pool = QThreadPool()
        self.inference_pool.setMaxThreadCount(1)  # æ¨ç†å•çº¿ç¨‹ï¼Œé¿å…æ˜¾å­˜å†²çª
        self.postprocess_pool = QThreadPool()
        self.postprocess_pool.setMaxThreadCount(2)  # åå¤„ç†å…è®¸å¹¶å‘


    def warmup_model(self):
        dummy_frame = np.zeros((320, 320, 3), dtype=np.uint8)
        try:
            self.model.SegImg(dummy_frame)
            self.log.info("âœ… æ¨¡å‹é¢„çƒ­å®Œæˆ")
        except Exception as e:
            self.log.error(f"æ¨¡å‹é¢„çƒ­å¤±è´¥: {e}")
    # åŠ è½½è§†é¢‘
    def Loadvideo(self):
        self.LoadModels()
        # è§†é¢‘æ–‡ä»¶è¿‡æ»¤å™¨
        video_filter = "è§†é¢‘æ–‡ä»¶ (*.mp4 *.avi *.mkv *.mov *.wmv *.flv *.webm);;æ‰€æœ‰æ–‡ä»¶ (*)"
        file_path, _ = QFileDialog.getOpenFileName( self.label,"é€‰æ‹©è§†é¢‘æ–‡ä»¶",".",video_filter)
        if file_path:
            self.log.info(f"âœ… é€‰ä¸­çš„è§†é¢‘è·¯å¾„: {file_path}")
            # è°ƒç”¨è§†é¢‘ åŠ è½½åˆ°UI
            self.PLAY(file_path)
        else:
            self.log.info("âŒ ç”¨æˆ·å–æ¶ˆé€‰æ‹©")
            return None
    def PLAY(self, video_path):
        # å…ˆåœæ­¢ä¹‹å‰çš„æ’­æ”¾
        self.timer.stop()
        if self.VS.is_opened:
            self.VS.release()

        # ç©ºä¸Šä¸€æ¬¡è§†é¢‘çš„æ¨ç†ç»“æœ
        # self.Outputlibrary.clear()  # æˆ–è€… = []
        # self.log.info("ğŸ—‘ï¸ å·²æ¸…ç©ºä¸Šä¸€æ¬¡çš„æ¨ç†ç»“æœåˆ—è¡¨")

        # æ‰“å¼€è§†é¢‘
        if not self.VS.open(SourceType.VIDEO, video_path):
            self.log.info("âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
            return
        # è·å–çœŸå® FPS
        fps = self.VS.cap.get(cv2.CAP_PROP_FPS)
        if fps <= 0:
            fps = 30  # é»˜è®¤å€¼
        self.delay_ms = int(1000 / fps)
        # å¯åŠ¨å®šæ—¶å™¨ï¼Œå¼€å§‹æ’­æ”¾
        self.timer.start(self.delay_ms)
    # ä¸»çº¿ç¨‹è§¦å‘
    def play_frame(self):
        """æ¯æ¬¡å®šæ—¶å™¨è§¦å‘ï¼Œæ’­æ”¾ä¸€å¸§"""
        ret, frame = self.VS.read()
        if not ret:
            self.log.info("ğŸ”š è§†é¢‘æ’­æ”¾ç»“æŸ")
            self.timer.stop()
            self.VS.release()
            self.label .clear()  # ä¸ç”¨çº¿ç¨‹æ˜¯ç”¨è¿™ä¸ªæ–¹æ³•
            return
        #DrawImage, Featuremask = self.model.SegImg(frame)
        #self.on_seg_done(DrawImage,Featuremask)
        # å¦‚æœå¡æ–­ å°†ä»£ç æ‰“å¼€
        # é˜²å †ç§¯ï¼šå¦‚æœå­çº¿ç¨‹è¿˜åœ¨è·‘ï¼Œè·³è¿‡è¿™ä¸€å¸§
        if self.inference_pool.activeThreadCount() > 0:
             self.log.info("è·³å¸§")
             return
        worker = SegWorker(self.model, frame)   # å°†æ¨¡å‹å’Œå¸§
        # è¿æ¥ä¿¡å·ï¼šç»“æœå›æ¥æ—¶æ›´æ–° UI
        worker.signals.result_ready.connect(self.on_seg_done)
        # çº¿ç¨‹æ± è‡ªåŠ¨åˆ†é…çº¿ç¨‹
        self.inference_pool.start(worker)



    def on_seg_done(self, rgb, output):
        # ä¸»çº¿ç¨‹æ‰§è¡Œï¼Œæ”¶åˆ°å­çº¿ç¨‹ç»“æœï¼Œæ›´æ–° UI outputæ¨ç†çš„æ‰€æœ‰å†…å®¹è®©åç«¯å¤„ç† å‰ååˆ†ç¦»
        h, w, c = rgb.shape
        q_image = QImage(rgb.data, w, h, 3 * w, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)
        self.label .setPixmap(pixmap)
        processor = OutputProcessorTask(output)
        # è¿æ¥ä¿¡å·
        processor.signals.finished.connect(self.MASKkIMG) # å¤„ç†åçš„ç»“æœ
        # ğŸ”¥ ç›´æ¥æ‰”è¿›çº¿ç¨‹æ± ï¼è®©å®ƒè‡ªå·±æ’é˜Ÿï¼
        self.postprocess_pool.start(processor)


    def MASKkIMG(self,MaskList):
        pass


    def LoadModels(self):
        if self.model is not None:
            self.model = None
            gc.collect()
            torch.cuda.empty_cache()
        self.model = SegModel()  # åŠ è½½æ–°æ¨¡å‹
        self.warmup_model()  # é¢„çƒ­

