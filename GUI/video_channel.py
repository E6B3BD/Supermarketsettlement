import sys
import os
import cv2
import gc
import torch
current_dir = os.path.dirname(os.path.abspath(__file__)) # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ä¸Šä¸€çº§ï¼ˆé¡¹ç›®æ ¹ç›®å½•ï¼‰
parent_dir = os.path.dirname(current_dir)  # å°±æ˜¯ project_root
sys.path.append(parent_dir) # å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ Python æ¨¡å—æœç´¢è·¯å¾„

from inference.segmentation.yolo_segment import SegModel

import time
from PySide2.QtCore import QObject
from PySide2.QtWidgets import QApplication, QWidget, QPushButton, QVBoxLayout, QFileDialog
from PySide2.QtGui import QImage, QPixmap
from PySide2.QtCore import Qt
from PySide2.QtCore import QTimer, QThreadPool
import numpy as np
import queue
import threading





# åŠ è½½æœ¬åœ°åŒ…
from .source.camera import VideoSource,SourceType
from .workers.seg_worker import SegWorker
from .workers.postprocess_worker import OutputProcessorTask

from logs.logger import DailyLogger
from utils.state import status
class VideoChannel(QObject):
    MAX_FEATURES = 30  # ä¾‹å¦‚æœ€å¤šå­˜å‚¨30å¼ 
    SKIP_INTERVAL = 2  # è·³å¸§é—´éš”ï¼Œå•ä½ä¸ºç§’
    def __init__(self, display_label,ui,status):
        super().__init__()
        self.label  = display_label  # æ‹¿åˆ°ç”»é¢çš„UI
        self.ui = ui
        self.log = DailyLogger("è§†é¢‘æºæ¨æµ")
        self.model = None
        self.VS = VideoSource()  # è§†é¢‘å¤„ç†
        self.timer = QTimer()  # è§†é¢‘æ’­æ”¾å®šæ—¶å™¨
        self.timer.timeout.connect(self.play_frame)  # æ¯æ¬¡è§¦å‘æ’­æ”¾ä¸€å¸§

        self.status=status
        self.feature=[] # å­˜å‚¨æ³¨å†Œç‰¹å¾çš„å›¾ç‰‡ åº”è¯¥è®¾ç½®æœ€å¤§å­˜å‚¨å¤šå°‘
        self.current_feature_index = -1  # å½“å‰æ˜¾ç¤ºçš„ç´¢å¼•ï¼Œ-1 è¡¨ç¤ºæ— å›¾
        self.last_added_time = None  # è®°å½•ä¸Šä¸€æ¬¡æ·»åŠ ç‰¹å¾å›¾çš„æ—¶é—´
        self.has_displayed_initial = False  # ğŸ”¥ æ–°å¢ï¼šæ˜¯å¦å·²è‡ªåŠ¨æ˜¾ç¤ºè¿‡åˆå§‹å›¾åƒ
        self.setup_feature_navigation()  # ç»‘å®šæŒ‰é’®äº‹ä»¶




        # self.threadpool = QThreadPool()  # çº¿ç¨‹æ±  ç®¡ç†å­çº¿ç¨‹
        # self.threadpool.setMaxThreadCount(3)  # 1 ä¸ªæ¨ç†çº¿ç¨‹ + 2 ä¸ªå¤„ç†çº¿ç¨‹
        self.inference_pool = QThreadPool()
        self.inference_pool.setMaxThreadCount(1)  # æ¨ç†å•çº¿ç¨‹ï¼Œé¿å…æ˜¾å­˜å†²çª
        self.postprocess_pool = QThreadPool()
        self.postprocess_pool.setMaxThreadCount(2)  # åå¤„ç†å…è®¸å¹¶å‘

    def setup_feature_navigation(self):
        """ç»‘å®šä¸Šä¸€å¼ ã€ä¸‹ä¸€å¼ ã€åˆ é™¤å½“å‰å¼ æŒ‰é’®"""
        self.ui.pushButton_16.clicked.connect(self.show_previous_feature)
        self.ui.pushButton_17.clicked.connect(self.show_next_feature)
        self.ui.pushButton.clicked.connect(self.delete_current_feature)

    def display_feature_at_index(self, index):
        """æ˜¾ç¤º feature åˆ—è¡¨ä¸­æŒ‡å®šç´¢å¼•çš„å›¾åƒ"""
        if not self.feature or index < 0 or index >= len(self.feature):
            self.ui.feature.clear()
            self.ui.feature.setText("æ— å›¾åƒ")  # å¯é€‰æç¤º
            self.current_feature_index = -1
            return
        self.current_feature_index = index
        feature_img = self.feature[index]

        try:
            h, w, c = feature_img.shape
            q_img = QImage(feature_img.data, w, h, 3 * w, QImage.Format_RGB888)
            pixmap = QPixmap.fromImage(q_img)

            if self.ui.feature:
                scaled_pixmap = pixmap.scaled(
                    self.ui.feature.size(),
                    Qt.KeepAspectRatio,
                    Qt.SmoothTransformation
                )
                self.ui.feature.setPixmap(scaled_pixmap)
                self.ui.feature.setAlignment(Qt.AlignCenter)
                self.log.info(f"âœ… æ˜¾ç¤ºç¬¬ {index + 1} å¼ ç‰¹å¾å›¾")
        except Exception as e:
            self.log.error(f"âŒ æ˜¾ç¤ºç‰¹å¾å›¾å¤±è´¥: {e}")
    # ä¸Šä¸€å¼ 
    def show_previous_feature(self):
        new_index = self.current_feature_index - 1
        if new_index < 0:
            self.log.info("â® å·²åˆ°ç¬¬ä¸€å¼ ")
            # å¯é€‰ï¼šå¾ªç¯æ’­æ”¾
            # new_index = len(self.feature) - 1
            return
        self.display_feature_at_index(new_index)
    # ä¸‹ä¸€å¼ 
    def show_next_feature(self):
        new_index = self.current_feature_index + 1
        if new_index >= len(self.feature):
            self.log.info("â­ å·²åˆ°æœ€åä¸€å¼ ")
            # å¯é€‰ï¼šå¾ªç¯æ’­æ”¾
            # new_index = 0
            return
        self.display_feature_at_index(new_index)
    # åˆ é™¤å½“å‰å¼ 
    def delete_current_feature(self):
        if self.current_feature_index < 0 or not self.feature:
            self.log.info("âŒ æ— å¯åˆ é™¤çš„ç‰¹å¾å›¾")
            return

        deleted = self.feature.pop(self.current_feature_index)
        self.log.info(f"ğŸ—‘ï¸ åˆ é™¤ç¬¬ {self.current_feature_index + 1} å¼ ç‰¹å¾å›¾")

        # åˆ é™¤åè‡ªåŠ¨æ˜¾ç¤ºä¸Šä¸€å¼ ï¼Œå¦‚æœå½“å‰æ˜¯ç¬¬ä¸€å¼ æˆ–æœ€åä¸€å¼ 
        if len(self.feature) == 0:
            self.display_feature_at_index(-1)  # æ¸…ç©ºæ˜¾ç¤º
        else:
            # ä¼˜å…ˆæ˜¾ç¤ºå‰ä¸€å¼ ï¼Œå¦‚æœå½“å‰æ˜¯æœ€åä¸€å¼ åˆ™æ˜¾ç¤ºæ–°çš„æœ€åä¸€å¼ 
            new_index = min(self.current_feature_index, len(self.feature) - 1)
            self.display_feature_at_index(new_index)





    def warmup_model(self):
        dummy_frame = np.zeros((320, 320, 3), dtype=np.uint8)
        try:
            self.model.SegImg(dummy_frame)
            self.log.info("âœ… æ¨¡å‹é¢„çƒ­å®Œæˆ")
        except Exception as e:
            self.log.error(f"æ¨¡å‹é¢„çƒ­å¤±è´¥: {e}")
    # åŠ è½½è§†é¢‘
    def Loadvideo(self):
        self.LoadModels()
        # è§†é¢‘æ–‡ä»¶è¿‡æ»¤å™¨
        video_filter = "è§†é¢‘æ–‡ä»¶ (*.mp4 *.avi *.mkv *.mov *.wmv *.flv *.webm);;æ‰€æœ‰æ–‡ä»¶ (*)"
        file_path, _ = QFileDialog.getOpenFileName( self.label,"é€‰æ‹©è§†é¢‘æ–‡ä»¶",".",video_filter)
        if file_path:
            self.log.info(f"âœ… é€‰ä¸­çš„è§†é¢‘è·¯å¾„: {file_path}")
            # è°ƒç”¨è§†é¢‘ åŠ è½½åˆ°UI
            self.PLAY(file_path)
        else:
            self.log.info("âŒ ç”¨æˆ·å–æ¶ˆé€‰æ‹©")
            return None
    def PLAY(self, video_path):
        # å…ˆåœæ­¢ä¹‹å‰çš„æ’­æ”¾
        self.timer.stop()
        if self.VS.is_opened:
            self.VS.release()

        # ç©ºä¸Šä¸€æ¬¡è§†é¢‘çš„æ¨ç†ç»“æœ
        # self.Outputlibrary.clear()  # æˆ–è€… = []
        # self.log.info("ğŸ—‘ï¸ å·²æ¸…ç©ºä¸Šä¸€æ¬¡çš„æ¨ç†ç»“æœåˆ—è¡¨")

        # æ‰“å¼€è§†é¢‘
        if not self.VS.open(SourceType.VIDEO, video_path):
            self.log.info("âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
            return
        # è·å–çœŸå® FPS
        fps = self.VS.cap.get(cv2.CAP_PROP_FPS)
        if fps <= 0:
            fps = 30  # é»˜è®¤å€¼
        self.delay_ms = int(1000 / fps)
        # å¯åŠ¨å®šæ—¶å™¨ï¼Œå¼€å§‹æ’­æ”¾
        self.timer.start(self.delay_ms)
    # ä¸»çº¿ç¨‹è§¦å‘
    def play_frame(self):
        """æ¯æ¬¡å®šæ—¶å™¨è§¦å‘ï¼Œæ’­æ”¾ä¸€å¸§"""
        ret, frame = self.VS.read()
        if not ret:
            self.log.info("ğŸ”š è§†é¢‘æ’­æ”¾ç»“æŸ")
            self.timer.stop()
            self.VS.release()
            self.label .clear()  # ä¸ç”¨çº¿ç¨‹æ˜¯ç”¨è¿™ä¸ªæ–¹æ³•
            return
        #DrawImage, Featuremask = self.model.SegImg(frame)
        #self.on_seg_done(DrawImage,Featuremask)
        # å¦‚æœå¡æ–­ å°†ä»£ç æ‰“å¼€
        # é˜²å †ç§¯ï¼šå¦‚æœå­çº¿ç¨‹è¿˜åœ¨è·‘ï¼Œè·³è¿‡è¿™ä¸€å¸§
        if self.inference_pool.activeThreadCount() > 0:
             self.log.info("è·³å¸§")
             return
        worker = SegWorker(self.model, frame)   # å°†æ¨¡å‹å’Œå¸§
        # è¿æ¥ä¿¡å·ï¼šç»“æœå›æ¥æ—¶æ›´æ–° UI
        worker.signals.result_ready.connect(self.on_seg_done)
        # çº¿ç¨‹æ± è‡ªåŠ¨åˆ†é…çº¿ç¨‹
        self.inference_pool.start(worker)



    def on_seg_done(self, rgb, output):
        # ä¸»çº¿ç¨‹æ‰§è¡Œï¼Œæ”¶åˆ°å­çº¿ç¨‹ç»“æœï¼Œæ›´æ–° UI outputæ¨ç†çš„æ‰€æœ‰å†…å®¹è®©åç«¯å¤„ç† å‰ååˆ†ç¦»
        h, w, c = rgb.shape
        q_image = QImage(rgb.data, w, h, 3 * w, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)
        self.label .setPixmap(pixmap)
        processor = OutputProcessorTask(output)
        # è¿æ¥ä¿¡å·
        processor.signals.finished.connect(self.MASKkIMG) # å¤„ç†åçš„ç»“æœ
        # ğŸ”¥ ç›´æ¥æ‰”è¿›çº¿ç¨‹æ± ï¼è®©å®ƒè‡ªå·±æ’é˜Ÿï¼
        self.postprocess_pool.start(processor)

    def MASKkIMG(self, MaskList):
        if not MaskList:
            self.log.debug("âš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•åˆ†å‰²ç‰¹å¾")
            return
        if self.status == status.Administrator and self.ui.radioButton.isChecked():
            current_time = time.time()
            # åˆå§‹åŒ– last_added_time
            if self.last_added_time is None:
                self.last_added_time = current_time
            # è·³å¸§é€»è¾‘ï¼šè·ç¦»ä¸Šæ¬¡æ·»åŠ ä¸è¶³ SKIP_INTERVAL ç§’åˆ™è·³è¿‡
            if current_time - self.last_added_time < self.SKIP_INTERVAL:
                self.log.info(f"â­ï¸ è·³è¿‡å½“å‰å¸§ï¼Œè·ç¦»ä¸Šæ¬¡æ·»åŠ  {current_time - self.last_added_time:.2f} ç§’")
                return
            self.last_added_time = current_time
            # æ£€æŸ¥æ˜¯å¦å·²è¾¾ä¸Šé™
            if len(self.feature) >= self.MAX_FEATURES:
                self.log.warning(f"âŒ ç‰¹å¾å›¾å·²è¾¾ä¸Šé™ {self.MAX_FEATURES} å¼ ï¼Œæ— æ³•ç»§ç»­æ·»åŠ ")
                return
            # æ·»åŠ æ–°ç‰¹å¾å›¾
            remaining = self.MAX_FEATURES - len(self.feature)
            features_to_add = MaskList[:remaining]
            if not features_to_add:
                return
            was_empty = len(self.feature) == 0  # æ·»åŠ å‰æ˜¯å¦ä¸ºç©º
            self.feature.extend(features_to_add)
            self.log.info(f"âœ… æ–°å¢ {len(features_to_add)} å¼ ç‰¹å¾å›¾ï¼Œå…± {len(self.feature)} / {self.MAX_FEATURES} å¼ ")
            # ğŸ”¥ ä»…å½“ï¼šåŸæ¥æ˜¯ç©ºçš„ï¼Œç°åœ¨æœ‰å›¾äº† â†’ è‡ªåŠ¨æ˜¾ç¤ºä¸€æ¬¡ï¼ˆæ¯”å¦‚æœ€åä¸€å¼ ï¼‰
            if was_empty and not self.has_displayed_initial:
                self.display_feature_at_index(-1)  # æ˜¾ç¤ºæœ€æ–°ä¸€å¼ 
                self.has_displayed_initial = True
                self.log.info("ğŸ“Œ åˆå§‹ç‰¹å¾å›¾å·²è‡ªåŠ¨æ˜¾ç¤ºï¼Œåç»­ä¸å†å¹²é¢„ç”¨æˆ·æµè§ˆ")

    def display_feature_at_index(self, index):
        """æ˜¾ç¤º feature åˆ—è¡¨ä¸­æŒ‡å®šç´¢å¼•çš„å›¾åƒ"""
        if not self.feature or index < 0 or index >= len(self.feature):
            self.ui.feature.clear()
            self.ui.feature.setText("æ— å›¾åƒ")  # å¯é€‰æç¤º
            self.current_feature_index = -1
            return

        self.current_feature_index = index
        feature_img = self.feature[index]

        try:
            h, w, c = feature_img.shape
            q_img = QImage(feature_img.data, w, h, 3 * w, QImage.Format_RGB888)
            pixmap = QPixmap.fromImage(q_img)

            if self.ui.feature:
                scaled_pixmap = pixmap.scaled(
                    self.ui.feature.size(),
                    Qt.KeepAspectRatio,
                    Qt.SmoothTransformation
                )
                self.ui.feature.setPixmap(scaled_pixmap)
                self.ui.feature.setAlignment(Qt.AlignCenter)
                self.log.info(f"âœ… æ˜¾ç¤ºç¬¬ {index + 1} å¼ ç‰¹å¾å›¾")
        except Exception as e:
            self.log.error(f"âŒ æ˜¾ç¤ºç‰¹å¾å›¾å¤±è´¥: {e}")







    def LoadModels(self):
        if self.model is not None:
            self.model = None
            gc.collect()
            torch.cuda.empty_cache()
        self.model = SegModel()  # åŠ è½½æ–°æ¨¡å‹
        self.warmup_model()  # é¢„çƒ­

